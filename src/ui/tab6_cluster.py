import io
import json
import streamlit as st
import pandas as pd
from agent.langGraph_gemini import stream_graph_updates2, stream_graph_updates
from ui.ui_main import get_cluster_labels


#-----------------------------------------------------------------------------------
# Tab 6 show_cluster_details
#-----------------------------------------------------------------------------------
def tab6_show_cluster_details(df_clustered, page_size=20):    
    st.markdown('**åˆ†ç¾¤çµæœ**')
    print("\n[Tab6], åˆ†ç¾¤çµæœ, df_clustered ===>\n", df_clustered)    
        
    # --- æ¯ä¸€å€‹ cluster çš„ç­†æ•¸ ---   
    cluster_counts, cluster_labels = get_cluster_labels(df_clustered)
    col1, col2 = st.columns([2, 1])
    with col1: 
        selected = st.selectbox('ğŸ“ˆ é¸æ“‡ç¾¤é›†', options=cluster_labels, key="cluster_select_label")
    
    # --- æ‰¾å‡ºæ‰€é¸çš„ cluster ---
    idx = cluster_labels.index(selected)
    cluster_index = cluster_counts.index[idx]
    df_cluster_selected = df_clustered[df_clustered['Cluster'] == cluster_index]
    print("\ndf_cluster_selected, Tab 6 ===>\n", df_cluster_selected)

    total = len(df_cluster_selected)
    total_pages = (total - 1) // page_size + 1 if total > 0 else 1         
    with col2: 
        page = st.number_input("ğŸ“ˆ é ç¢¼", min_value=1, max_value=total_pages, value=1, step=1, key="cluster_page_num")    
        
    start = (page - 1) * page_size
    end = start + page_size        
    st.write(f'ğŸ“ˆ ç¾¤ {cluster_index} (count={total}) - ç¬¬ {page}/{total_pages} é ')
    
    # --- é¡¯ç¤ºè©²ç¾¤çš„è³‡æ–™ ---
    df = df_cluster_selected.iloc[start:end].copy()
    format_mapping = {
        'å…¬å¸ä»£è™Ÿ': '{}', # å­—ä¸²      
        'åç¨±': '{}',                     
        # ç²åˆ©/æ¯”ç‡ (å»ºè­° 4 ä½å°æ•¸ï¼Œç¢ºä¿ç²¾ç¢ºåº¦)
        'ROE': '{:.1%}',
        'æ¯›åˆ©ç‡': '{:.1%}',
        'ç´”ç›Šç‡': '{:.1%}',
        'ç‡Ÿæ¥­åˆ©ç›Šç‡': '{:.1%}',
        'ç¾é‡‘æ®–åˆ©ç‡': '{:.1%}',
        'é«˜ç™»': '{:.1%}',
        'ç¸½è³‡ç”¢å‘¨è½‰ç‡': '{:.1%}',        
        # æˆé•·ç‡/è¼ƒå¤§æ¯”ç‡
        'ç›ˆé¤˜æˆé•·ç‡': '{:.1%}',
        'ç‡Ÿæ”¶å¹´æˆé•·ç‡': '{:.1%}',        
        # é‡‘é¡/è¼ƒå¤§æ•¸å€¼ (å»ºè­° 2 ä½å°æ•¸)
        'EPS': '{:.2f}',
        'FCF': '{:.2f}',
        'æ¯è‚¡æ·¨å€¼': '{:.1f}',
        'æ¬Šç›Šä¹˜æ•¸': '{:.1%}',     
        'è‚¡æœ¬å„„å…ƒ': '{:,.0f}',   
        # å€æ•¸ (å»ºè­° 2 ä½å°æ•¸)
        'PBR': '{:.1f}',
        'PER': '{:.1f}',        
        # æ³¢å‹•æ€§ (æ•¸å€¼è¼ƒå¤§ï¼Œå»ºè­° 2 ä½å°æ•¸)
        'è‚¡åƒ¹æ¨™æº–å·®': '{:.1f}',
        'è‚¡åƒ¹è®Šç•°æ•¸': '{:.1f}', 
        'å¹³å‡åƒ¹': '{:.1f}',       
        # åˆ†ç¾¤æ¨™ç±¤
        'Cluster': '{}'
    } 
    
    new_order = ['Cluster','å…¬å¸ä»£è™Ÿ','åç¨±','ROE','æ¯›åˆ©ç‡','ç‡Ÿæ¥­åˆ©ç›Šç‡','ç´”ç›Šç‡', 'ç¸½è³‡ç”¢å‘¨è½‰ç‡', 'æ¬Šç›Šä¹˜æ•¸','ç›ˆé¤˜æˆé•·ç‡','é«˜ç™»','ç‡Ÿæ”¶å¹´æˆé•·ç‡','ç¾é‡‘æ®–åˆ©ç‡','EPS']
    df = df.reindex(columns=new_order + [col for col in df.columns if col not in new_order])
    
    styled_df = df.style.format(format_mapping, na_rep='-') 
    selected_rows_dict = st.dataframe(
        styled_df,
        hide_index=True,
        on_select="rerun",
        selection_mode="single-row"        
    )   
    
    # --- æä¾›ä¸‹è¼‰è©²ç¾¤ Excel ---
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df_cluster_selected.to_excel(writer, index=False, sheet_name=f'cluster_{cluster_index}')
        
    excel_data = buffer.getvalue()
    st.download_button(
        label="ğŸ“ˆ ä¸‹è¼‰è©²ç¾¤çµæœ Excel",
        data=excel_data,
        file_name=f"cluster_{cluster_index}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    
    # --- å–å¾—é¸å–åˆ°çš„è³‡æ–™, å¦‚æœæœ‰ä»»ä½•ä¸€è¡Œè¢«é¸å– ---
    selected_indices = selected_rows_dict.get('selection', {}).get('rows', [])
    if selected_indices:
        # å–å¾—è¢«é¸å–çš„åˆ—çš„ç´¢å¼•
        print("\né¸å–åˆ°çš„è³‡æ–™, selected_indices ===>\n", selected_indices, "\n")
        selected_row_index = selected_indices[0]       
        selected_row_data = df.iloc[selected_row_index]        
        print("\né¸å–åˆ°çš„è³‡æ–™m selected_row_data ===>\n", selected_row_data, "\n")
        
        # å–å¾—ç‰¹å®šæ¬„ä½çš„å€¼
        selected_id = selected_row_data['å…¬å¸ä»£è™Ÿ']
        selected_name = selected_row_data['åç¨±']
        print("\nå–å¾—é¸å–åˆ°çš„è³‡æ–™ ===>\nselected_id= ", selected_id, ", selected_name= ", selected_name, "\n")
        
        # --- Use LangGraph --- and https://money.udn.com/
        user_input = f"""
            Search and summary Taiwan stock: {str(selected_id)}.TW for recent stock price, company profile, operation and news.             
            Include domain: https://tw.stock.yahoo.com/, https://www.cnyes.com/ and https://www.ctee.com.tw/.  
            And answer in Traditional Chinese.                                              
            """  
            
        # with st.status("ğŸŒ LangGraph æœå°‹ä¸­...", expanded=True) as status:  
        #     # 2. å»ºç«‹ä¸€å€‹èŠå¤©è¨Šæ¯å€å¡Šï¼Œé¡¯ç¤º AI çš„å›æ‡‰
        #     with st.chat_message("assistant"):
        #         # st.write_stream æœƒæ¥æ”¶ stream_graph_updates ç”¢å‡ºçš„å…§å®¹ä¸¦å³æ™‚é¡¯ç¤º
        #         # response_generator æ˜¯æˆ‘å€‘ä¸Šé¢ä¿®æ”¹å¾Œçš„ generator
        #         response_generator = stream_graph_updates2(user_input)
                
        #         # *** é—œéµä¿®æ”¹ï¼šä½¿ç”¨ st.write_stream è™•ç† generator ***
        #         full_response = st.write_stream(response_generator)
                
        #     # 3. ç‹€æ…‹å®Œæˆ (å¯ä»¥é¸æ“‡æ€§åœ°éš±è— statusï¼Œæˆ–ä¿æŒé¡¯ç¤º)
        #     status.update(label="ğŸ“‚ AI è§£é‡‹", state="complete", expanded=True)
            
        #     # å‚™è¨»ï¼šå¦‚æœä½ éœ€è¦ä¿ç•™å®Œæ•´çš„ full_response (ä¾‹å¦‚ç”¨æ–¼å¿«å–)ï¼Œ
        #     # st.write_stream() æœƒå›å‚³æ‰€æœ‰ç‰‡æ®µæ‹¼æ¥èµ·ä¾†çš„å®Œæ•´å­—ä¸²ã€‚
            
        with st.status("ğŸŒ LangGraph æœå°‹ä¸­...", expanded=True) as status:              
            all_messages, last_msg = stream_graph_updates(user_input)                               
            if all_messages:
                status.update(label="ğŸŒ LangGraph ä»»å‹™å·²å®Œæˆï¼", state="complete", expanded=True)     
                for message in all_messages: 
                    try:        
                        data = json.loads(message)  
                        if data:
                            with st.expander("ğŸ“‚ AI Agent é€é TavilySearch æœå°‹åˆ°çš„è³‡æ–™"):                                     
                                for result in data.get('results', []):
                                    with st.container():
                                        st.markdown(f"**[{result.get('title', 'ç„¡æ¨™é¡Œ')}]({result.get('url', '#')})**")
                                        st.markdown(f"*{result.get('content', 'ç„¡æ‘˜è¦')}*")
                                    
                    except json.JSONDecodeError:
                        # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå°±ç•¶ä½œæ™®é€šæ–‡å­—é¡¯ç¤º    
                        with st.expander("ğŸ“¦ AI Agent ç¸½çµæœå°‹åˆ°çš„è³‡æ–™"):
                            st.write(message)
        
    